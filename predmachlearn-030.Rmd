---
title: "Practical Machine Learning 030 - Writeup Assignment"
author: "Maurizio Pinto"
output: 
  html_document:
    keep_md: true
---

```{r, echo=FALSE, message=FALSE}
library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(xtable)
```

##Synopsis

The goal of this project is to use the Weight Lifting Exercises dataset (see the References section) to investigate "how (well)" an activity (barbell lift) was performed by 6 participants. Data has been collected by means of on-body sensing approach and the participants were asked one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashion:

* exactly according to the specification (Class A)
* throwing the elbows to the front (Class B)
* lifting the dumbbell only halfway (Class C)
* lowering the dumbbell only halfway (Class D)
* throwing the hips to the front (Class E)

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

Read more at the Groupware LES website [http://groupware.les.inf.puc-rio.br/har#wle_paper_section](http://groupware.les.inf.puc-rio.br/har#wle_paper_section)


##Loading and Processing the Raw Data

The training data for this project are available here: 

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv)

The test data are available here: 

[https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv)

An initial analysis of the dataset reveals that missing values are marked as "NA", empty string, or "#DIV/0!". The files are therefore loaded into memory.

```{r}
training <- read.csv("data/pml-training.csv", na.strings = c("NA", "", "#DIV/0!"))
testing <- read.csv("data/pml-testing.csv", na.strings = c("NA", "", "#DIV/0!"))
```

The dimensions of the datasets are:

* training: `r nrow(training)` observations of `r ncol(training)` variables
* testing: `r nrow(testing)` observations of `r ncol(testing)` variables

Many columns contain more that 90% of missing values: since those variables would not be useful for our model, we remove them.

```{r}
training <-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]
```

* training: `r nrow(training)` observations of `r ncol(training)` variables
* testing: `r nrow(testing)` observations of `r ncol(testing)` variables

We realize as well that the first seven columns (*X*, *user_name*, *raw_timestamp_part_1*, *raw_timestamp_part_2*, *cvtd_timestamp*, *new_window*, *num_window*) contain variables that are not useful for our model (e.g. the participant name). We then remove them from the dataset.

```{r}
training   <- training[,-c(1:7)]
testing <- testing[,-c(1:7)]
```

* training: `r nrow(training)` observations of `r ncol(training)` variables
* testing: `r nrow(testing)` observations of `r ncol(testing)` variables

The datasets are now ready for the modeling stage.

##Build a predictive model

###Decision tree

We begin with partitioning the first set into training and validation sets (60% for training, 40% for testing):

```{r}
set.seed(1701)
partition <- createDataPartition(y=training$classe, p=0.6, list=FALSE)
subTraining <- training[partition, ] 
subTesting <- training[-partition, ]
```

We first implement a model by means of a decision tree:

```{r}
modeldc <- rpart(classe ~ ., data=subTraining, method="class")
predictiondc <- predict(modeldc, subTesting, type = "class")
rpart.plot(modeldc, main="Classification Tree")
print(confusionMatrix(predictiondc, subTesting$classe))
accuracydc <- sum(predictiondc == subTesting$classe) / nrow(subTesting)
osedc <- 1-accuracydc
```

The accuracy of our first model is only `r accuracydc` and the Out-of-Sample error is `r osedc`, so we build a new model based on random forests for better results.

###Random forests

```{r}
modelrf <- randomForest(classe ~. , data=subTraining, method="class")
predictionrf <- predict(modelrf, subTesting, type = "class")
print(confusionMatrix(predictionrf, subTesting$classe))
accuracyrf <- sum(predictionrf == subTesting$classe) / nrow(subTesting)
oserf <- 1-accuracyrf
```

The accuracy of our second model is good `r accuracyrf` and the Out-of-Sample error is `r oserf` , therefore we choose this one as our predictive model.

##Results

The model based on random forests can now be applied to the testing dataset:

```{r}
predictfinal <- predict(modelrf, testing, type="class")
print(predictfinal)
```


##References

Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
